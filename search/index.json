[{"content":"Ce TP est une introduction à l\u0026rsquo;IA à destination de lycéens ayant des bases en Python. Il consiste à entraîner sur différents jeux de données un modèle d\u0026rsquo;IA qui prédit le trafic sur la ville de Rennes. Les jeux de données sont stockés sur un noeud RUDI, et issus du portail open data de la ville de Rennes. Le TP permet d\u0026rsquo;appréhender le mécanisme général d\u0026rsquo;entraînement d\u0026rsquo;un IA ainsi que la visualisation de données (géographiques). Le TP est disponible sur GitHub, ici.\n","date":"0001-01-01T00:00:00Z","image":"https://demo.stack.jimmycai.com/post/prediction_trafic/map.jpg","permalink":"https://demo.stack.jimmycai.com/p/activit%C3%A9-dia-pr%C3%A9diction-du-trafic-de-rennes/","title":"Activité d'IA, prédiction du trafic de Rennes"},{"content":"Le jeu Cops and Robber est un jeu de poursuite sur un graphe. On choisit un ensemble de sommets, certains reliés entre eux par des arêtes (c\u0026rsquo;est-à-dire un graphe). Le premier joueur (le policier) choisit alors un sommet de départ, puis le second joueur (le voleur) fait de même. Chacun leur tour, ils se déplacent sur un sommet voisin, jusqu\u0026rsquo;à ce qu\u0026rsquo;éventuellement le policier arrive sur la même case que le voleur. On dit alors que le policier a gagné.\nLe (très chouette) livre \u0026lsquo;The Game of Cops and Robber on Graphs\u0026rsquo;, d\u0026rsquo;Anthony Bonato et Richard J. Nowakowski présente toute une théorie autour de ce jeu. On peut par exemple se demander si, pour un certain graphe fixé, le policier peut toujours gagner. Si non, on peut alors se demander combien de policiers il faudrait pour attraper le voleur à coup sûr.\nPour essayer ce jeu sur vos graphes favoris, une version Python du jeu est disponible ici.\nIl dispose d\u0026rsquo;un éditeur de graphes, pour créer et modifier vos terrains de jeu.\nLe jeu a été codé avec la librairie pygame.\n","date":"0001-01-01T00:00:00Z","image":"https://demo.stack.jimmycai.com/post/cops_robber/cops_robber_img.png","permalink":"https://demo.stack.jimmycai.com/p/cops-and-robber-le-jeu-python/","title":"Cops and Robber - Le jeu Python"},{"content":"Dans le cadre du TP autour de la prédiction du trafic de la ville de Rennes, le modèle \u0026lsquo;Naive Bayes\u0026rsquo; est utilisé. On détaille ici un peu plus la théorie derrière la pratique.\nReprenons l\u0026rsquo;exemple de l\u0026rsquo;état du trafic. Pour simplifier, on suppose qu\u0026rsquo;on a 2 entrées : nom_de_la_route et heure; et une sortie : etat_trafic. Les différentes valeurs possibles pour etat_trafic sont :\ncirculation_impossible tres_ralenti ralenti fluide Pour résumer, le modèle Naïve Bayes essaye d\u0026rsquo;estimer, pour une entrée $x = $(nom_de_la_route, heure) la probabilité que la sortie soit chacune des 4 possibilités. Il retourne ensuite la valeur pour laquelle il a estimé la plus grande probabilité.\nDe manière plus précise, on modélise notre problème par un couple $(X, Y)$ de variables aléatoires vérifiant :\n$X$ est à valeur dans $\\mathcal X = \\mathcal D\\times \\mathcal H$, où $\\mathcal D$ est l\u0026rsquo;ensemble des noms de route possibles et $\\mathcal H$ l\u0026rsquo;ensemble des heures ({0, 1, \u0026hellip;, 23}), $Y$ est à valeur dans $\\mathcal Y$, l\u0026rsquo;ensemble des valeurs possibles du trafic. On encode pour la suite ces valeurs en $1, 2, 3$ et $4$. Le modèle fonctionne de la manière suivante. Pour $x \\in \\mathcal X$, le modèle estime (à un facteur près) :\n$p_1$$ = \\mathbb{P} (Y = 1 | X = x)$, $p_2$$ = \\mathbb{P} (Y = 2 | X = x)$, $p_3$$ = \\mathbb{P} (Y = 3 | X = x)$, $p_4$$ = \\mathbb{P} (Y = 4 | X = x)$. Puis il regarde laquelle de ces $4$ estimations est la plus grande, et retourne le choix corespondant.\nC\u0026rsquo;est la manière dont le modèle estime les paramètres qui lui donne son nom (Naïve Bayes). Elle est basée sur le théorème de Bayes, et est dite \u0026lsquo;Naïve\u0026rsquo; car elle fait une hypothèse assez forte sur $X$ (on explique pourquoi on fait cette hypothèse à la fin).\n\u0026lsquo;Naïve\u0026rsquo; ? Pour estimer les probabilités ci-dessus, le modèle fait l\u0026rsquo;hypothèse que les marginales de $X$ sont indépendantes conditionnellement à $Y$. C\u0026rsquo;est-à-dire, (si on note $X^{(1)}$ le nom de la route et $X^{(2)}$ l\u0026rsquo;heure) que pour tout nom de route $x^{(1)} \\in \\mathcal D$ , toute heure $x^{(2)} \\in \\mathcal H$ et toute valeur $y \\in \\mathcal Y$ de l\u0026rsquo;état du trafic, on a : $$ \\mathbb P(X^{(1)} = x^{(1)}, X^{(2)} = x^{(2)} | Y = y) = \\mathbb P(X^{(1)} = x^{(1)}| Y = y)\\times \\mathbb P( X^{(2)} = x^{(2)} | Y = y). $$\nOn rappelle que par définition, la probabilité que $X^{(1)} = x^{(1)}$ sachant que $Y=y$ est : $$ \\mathbb P(X^{(1)} = x^{(1)}| Y = y) = \\frac{\\mathbb P(X^{(1)} = x^{(1)}, Y = y)}{\\mathbb P(Y = y)} $$\nIntuitivement, dire que $X^{(1)}$ et $X^{(2)}$ sont indépendantes conditionnellement à $Y$ peut être expliqué de la manière suivante. Imaginons que vous jouez avec une amie. Elle observe l\u0026rsquo;état du trafic sur une route, à une heure précise. Elle vous dit quel est l\u0026rsquo;état de la circulation, mais pas le nom de la route, ni l\u0026rsquo;heure. Vous devez alors deviner (au hasard) ces deux informations. Alors dans cette configuration, dire que $X^{(1)}$ et $X^{(2)}$ sont indépendantes conditionnellement à $Y$ c\u0026rsquo;est dire que le fait de connaître (en plus de l\u0026rsquo;état du trafic) le nom de la route n\u0026rsquo;influence pas votre supposition sur l\u0026rsquo;heure (ou de manière équivalente que connaître l\u0026rsquo;heure n\u0026rsquo;influence pas votre supposition sur le nom de la route).\nCette hypothèse est souvent très forte (d\u0026rsquo;où la dénomination \u0026rsquo;naïve\u0026rsquo;), même si elle ne semble pas l\u0026rsquo;être dans cet exemple précis.\n\u0026lsquo;Bayes\u0026rsquo; ? Le théorème de Bayes fait le lien entre $\\mathbb P (Y = y | X = x)$ et $\\mathbb P (X = x | Y = y)$. Voici ce théorème : $$ \\mathbb P (Y = y | X = x) = \\frac{\\mathbb P (X = x | Y = y)\\times \\mathbb P(Y = y)}{\\mathbb P(X = x)} $$ Il permet ici, si on fait l\u0026rsquo;hypothèse d\u0026rsquo;indépendance des marginales conditionnellement à $Y$, d\u0026rsquo;estimer les probabilités $p_1, p_2, p_3, p_4$.\nEstimer les probabilités ? Pour estimer les 4 probabilités $p_1, p_2, p_3, p_4$, une première approche peut être la suivante. Par définition de la probabilité conditionnelle : $$ \\mathbb p_1 = \\mathbb P(Y = 1 | X = x) = \\frac{\\mathbb P(Y = 1, X = x)}{\\mathbb P(X = x)}. $$ Si on dispose de $n$ données d\u0026rsquo;entraînement $(x_1, y_1), \u0026hellip;, (x_n, y_n)$ (c\u0026rsquo;est-à-dire un tableau de données comme dans l\u0026rsquo;exercice !). On note $N_1(n)$ le nombre de fois où on observe $(x, 1)$ dans ces données, on peut alors approcher $\\mathbb P(Y = 1, X = x)$ (grâce à la loi des grands nombres) par $\\frac{N_1(n)}{n}$. Il est inutile d\u0026rsquo;avoir une approximation du dénominateur, $\\mathbb P(X = x)$, car il va apparaître dans chacune des $4$ probabilités $p_1, p_2, p_3, p_4$ : on peut se contenter de choisir l\u0026rsquo;état $i$ du trafic pour lequel la probabilité $\\mathbb P(Y = i, X = x)$ est la plus grande (ça sera la même que celle pour laquelle $p_i$ est la plus grande). Le potentiel problème de cette première approche est le suivant: si on a beaucoup de paramètres en entrées (c\u0026rsquo;est-à-dire si $X$ est à valeur dans un espace avec un grand nombre de dimensions), le nombre $N_1(n)$ de fois où on a observé l\u0026rsquo;entrée $x$ et la sortie $1$ risque d\u0026rsquo;être trop petit pour fournir une bonne approximation de $\\mathbb P(Y = 1, X = x)$ (ou alors il faudrait un nombre $n$ de données d\u0026rsquo;entraînement beaucoup trop grand).\nC\u0026rsquo;est pour palier à ce problème qu\u0026rsquo;on fait l\u0026rsquo;hypothèse \u0026rsquo;naïve\u0026rsquo; d\u0026rsquo;indépendance conditionnelle. Dans ce cas, l\u0026rsquo;approximation de $p_1$ se simplifie. Par le théorème de Bayes : $$ p_1 = \\mathbb P(X = x| Y = 1) \\times \\frac{\\mathbb P(Y = 1)}{\\mathbb P(X = x)}. $$ Par l\u0026rsquo;hypothèse d\u0026rsquo;indépendance conditionnelle : $$ \\mathbb P(X = x | Y = 1) = \\mathbb P(X^{(1)} = x^{(1)}| Y = 1)\\times \\mathbb P( X^{(2)} = x^{(2)} | Y = 1). $$ Pour estimer chacun des deux termes du produit, on peut utiliser la loi des grands nombres comme précedemment. Par exemple, $\\mathbb P(X^{(1)} = x^{(1)}| Y = 1)$ peut être approché par $\\frac{N^{(1)}_1(n)}{M_1(n)}$, où $N^{(1)}_1(n)$ est le nombre de fois où on a observé la caractéristique $x^{(1)}$ et l\u0026rsquo;état du trafic $1$ parmi les données d\u0026rsquo;entraînement (par exemple le nombre de fois où la circulation était impossible sur le Mail François Mitterand), et $M_1(n)$ est le nombre de fois où on a observé l\u0026rsquo;état du trafic $1$ parmi les données d\u0026rsquo;entraînement (c\u0026rsquo;est-à-dire le nombre de fois où on a observé que la circulation était impossible). Cela permet de séparer les caractéristiques en entrée, au prix d\u0026rsquo;une hypothèse forte d\u0026rsquo;indépendance.\nQuelques références\nhttps://fr.wikipedia.org/wiki/Classification_na%C3%AFve_bay%C3%A9sienne\nhttps://scikit-learn.org/stable/modules/naive_bayes.html\nhttps://youtu.be/HlsrPlGmW00?si=0F5RHxFFfxo-G0Pw\n","date":"0001-01-01T00:00:00Z","image":"https://demo.stack.jimmycai.com/post/documents/naive_bayes/image.png","permalink":"https://demo.stack.jimmycai.com/p/explication-du-mod%C3%A8le-na%C3%AFve-bayes/","title":"Explication du modèle Naïve Bayes"},{"content":"Mon stage de fin de M1 portait sur des processus de branchement en temps discret. Le mémoire de stage est disponible ici.\nIl a été réalisé à l\u0026rsquo;Université du Québec à Montréal, sous la direction d\u0026rsquo;Hélène Guérin et de Félix Foutel-Rodier.\nLes processus étudiés pendant le stage sont des modèles probabilistes, qui peuvent permettre par exemple de décrire l\u0026rsquo;évolution d\u0026rsquo;une population, ou bien la propagation d\u0026rsquo;une épidémie. Le modèle le plus classique est celui des processus de Galton-Watson, introduit au 19e siècle, qui ont été étudiés dans la première partie du stage. La construction d\u0026rsquo;un espace de probabilité d\u0026rsquo;arbres aléatoires apparaît au 20e siècle, parfois due à Neveu, parfois à Ulam et Harris, et permet de mieux comprendre certains résultats sur ces processus. En particulier, le Théorème de Kesten et Stigum se montre à l\u0026rsquo;aide d\u0026rsquo;une technique de décomposition épinale. Cette méthode, présentée initialement par Lyons, Pemantle et Peres dans l\u0026rsquo;article [RLP95] a l\u0026rsquo;avantage de se généraliser à des modèles plus complexes, comme ceux étudiés dans la fin du stage : les processus de Crump-Mode-Jagers. Ce modèle est plus réaliste que celui de Galton-Watson, mais plus complexe à étudier.\nProcessus de Galton-Watson Partons d\u0026rsquo;un groupe d\u0026rsquo;individus, et imaginons qu\u0026rsquo;ils donnent naissance indépendamment les uns des autres à un nombre aléatoire d\u0026rsquo;enfants, suivant la même mesure de probabilité $P$, puis meurent. Appelons ces individus la génération 0, et leurs enfants la génération 1. On peut recommencer le processus pour chaque individu de la génération 1, et obtenir la génération 2, et ainsi de suite. Les processus de Galton-Watson modélisent ce genre de situation. C\u0026rsquo;est-à-dire que les générations sont séparées, les individus ne se reproduisent pas entre eux, mais donnent naissance tous seuls à des enfants (on parle de reproduction asexuée), et ce une seule fois dans leur vie. Un outil utile pour visualiser l\u0026rsquo;évolution d\u0026rsquo;un tel processus est un arbre aléatoire. Ici, la génération 0 est représentée en noir, la première en rouge et la seconde en bleu.\nProcessus de Crump-Mode-Jaggers (CMJ) Les processus CMJ sont plus complexes. Dans ce modèle, les individus donnent naissance au cours de leur vie à plusieurs enfants, à des dates précises. Ceci change l\u0026rsquo;échelle de temps, qui compte plutôt les années que les générations, car ces dernières peuvent désormais se superposer. Ci-dessous, on a représenté un exemple d\u0026rsquo;évolution d\u0026rsquo;une population selon ce modèle. Chaque ligne colorée représente la vie d\u0026rsquo;un individu, et chaque individu est noté par un point. L\u0026rsquo;axe des abcisses représente le temps.\n[RLP95] Robin Pemantle, Russell Lyons and Yuval Peres. Conceptual proofs of LlogL criteria for mean behaviour of branching processes. The Annals of Probability, 23(3) :1125 – 1138, 1995.\n","date":"0001-01-01T00:00:00Z","image":"https://demo.stack.jimmycai.com/post/documents/stage_m1/arbre_biaise.png","permalink":"https://demo.stack.jimmycai.com/p/processus-de-branchement-en-temps-discret-et-d%C3%A9composition-%C3%A9pinale/","title":"Processus de branchement en temps discret et décomposition épinale"},{"content":"Le théorème présenté est un joli résultat liant les matrices stochastiques et les groupes, en passant par les valeurs propres et les nombres complexes de module 1 (ce qui en fait un beau développement pour l\u0026rsquo;agrégation de mathématiques !). Il existe différentes versions du théorème de Perron-Frobenius, selon les hypothèses sur la matrice. Celle présentée nous donne des informations sur le spectre des matrices stochastiques irréductibles. Plus précisément, on montre le théorème suivant :\nThéorème : Soit $A \\in \\mathcal M_n(\\mathbb R)$ une matrice stochastique et irréductible. Alors le rayon spectral de $A$ est 1, et l\u0026rsquo;ensemble des valeurs propres (complexes) de $A$ de module 1 forme un sous-groupe de $(\\mathbb S^1, .)$.\nOn montre même plus précisément, pour $\\lambda$ et $\\mu$ deux valeurs propres de module 1 de vecteurs propres respectifs $X$ et $Y$; que le vecteur $X.Y := (X_k.Y_k)_k$ est un vecteur propre pour $\\lambda.\\mu$ !\nLa preuve du théorème est disponible ici.\nRéférences : Serge Francinou, Hervé Gianella et Serge Nicolas. Oraux X-ENS, Algèbre 2. Pages 83-85. Denis Serre. Les Matrices, Théorie et pratique. 2001 ","date":"0001-01-01T00:00:00Z","image":"https://demo.stack.jimmycai.com/post/documents/devs/perron_frobenius/perron_frobenius.png","permalink":"https://demo.stack.jimmycai.com/p/un-th%C3%A9or%C3%A8me-de-perron-frobenius/","title":"Un théorème de Perron-Frobenius"}]